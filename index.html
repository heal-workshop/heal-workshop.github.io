<!DOCTYPE html>
<html lang="en">
<title>HEAL@CHI'25</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://unpkg.com/tachyons/css/tachyons.min.css">
<link rel="stylesheet" href="./style.css">

<script>
    document.addEventListener('DOMContentLoaded', function() {
    const readMoreBtn = document.querySelector('.read-more');
    const readLessBtn = document.querySelector('.read-less');
    const bioHidden = document.querySelector('.bio-hidden');

    readMoreBtn.addEventListener('click', function() {
        bioHidden.style.display = 'block';
        readMoreBtn.style.display = 'none';
    });

    readLessBtn.addEventListener('click', function() {
        bioHidden.style.display = 'none';
        readMoreBtn.style.display = 'inline';
    });
});
</script>

<body class="sans-serif">
    <header class="sans-serif">
        <div class="cover bg-left bg-center-l accent-bg" style="background-image: url('assets/chi2025_banner_no_text.svg');">
            <div class="pb4 pb4-m pb4-l">
                <nav class="dt w-100 mw8 center">
                    <div class="dtc w6 v-mid pa1">
                        <a href="" class="f4 fw5 dib no-underline grow white pa2 grow">
                            HEAL@CHI'25
                        </a>
                    </div>
                    <div class="dtc v-mid tr pa3">
                        <a class="f6 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="#cfp">Call for
                            Participation</a>
                        <a class="f6 fw4 hover-white no-underline white-70 dn dib-l pv2 ph3" href="#info">Key Information</a>
                        <a class="f6 fw4 hover-white no-underline white-70 dn dib-l pv2 ph3" href="#agenda">Agenda</a>
                        <a class="f6 fw4 hover-white no-underline white-70 dn dib-l pv2 ph3" href="chi2024.html">CHI 2024</a>
                    </div>
                </nav>
                <div class="tc-l mt4 mt5-m mt6-l ph5 w-75 center">
                    <h1 class="f2 f1-l fw6 white-90 mb0 lh-title"><b>HEAL @ CHI 2025</b><br><b>H</b>uman-centered <b>E</b>valuation and<br><b>A</b>uditing of <b>L</b>anguage Models</h1>
                    <h2 class="fw3 f3 white-80 mt3 mb4">Yokohama, Japan | April 26, 2025</h2>
                    <h3 class="fw3 f3 white-90 mt3 mb4 white accent-bg">Submission Deadline: <strong> <del>February 17</del> February 24, 2025 (AOE)</strong></h3>
                    <a class="f6 link grow br3 ba bw1 ph3 pv2 mb2 dib accent-txt bg-white" href="https://openreview.net/group?id=ACM.org/CHI/2025/Workshop/HEAL" target="_blank">→ <b>Submission Site</b></a>
                </div>
            </div>
        </div>
    </header>

    <div class="text-section-padded">
        <article class="cf ph3 ph5-ns pv5" id="overview">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Overview
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <p class="f5 lh-copy mt0-ns">
                <b>HEAL is back for CHI 2025!</b> This workshop aims to address the current ''evaluation crisis'' in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The recent advancements in Large Language Models (LLMs) have significantly impacted numerous and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential.
                </p>
                <p class="f5 lh-copy">
                The <b>CHI 2025 Workshop</b> on <b>H</b>uman-centered <b>E</b>valuation and <b>A</b>uditing of <b>L</b>anguage Models (<b>HEAL@CHI'25</b>) will explore topics around understanding stakeholders' needs and goals with evaluation and auditing LMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community, and fostering collaboration
                </p>
                <p class="f5 lh-copy">
                <b>Special Theme - Mind the Context</b>: For this year’s HEAL, we introduce the theme of ''mind the context'' to encourage attendees to engage with specific contexts in LLM evaluation and auditing. This theme involves various topics: the usage contexts of LLMs (e.g., evaluating the capabilities and limitations of LLM applications in mental wellness care, or translation in high-stakes scenarios), the context of the evaluation/auditing itself (e.g., who are using LLM evaluation tools, and how should we design these tools with this context in mind?), and more. We purposefully leave ''context'' open for interpretation by participants, so to encourage diversity in how participants conceptualize and operationalize this key concept in LLM evaluation and auditing.
                </p>
            </div>
        </article>

        <article class="cf ph3 ph5-ns pv5" id="keynote">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Keynote Speakers
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <div class="speaker-container">
                    <div class="speaker-photo">
                        <div class="aspect-ratio aspect-ratio--1x1">
                            <img src="./assets/sulin.png" class="db bg-center cover aspect-ratio--object br-100" alt="Afternoon Keynote Speaker">
                        </div>
                    </div>

                    <div class="speaker-info">
                        <h2>Dr. Su Lin Blodgett</h2>
                        <p>
                            Dr. Su Lin Blodgett is a senior researcher in the Fairness, Accountability, Transparency, and Ethics in AI (FATE) group at Microsoft Research Montréal. She is broadly interested in examining the social and ethical implications of natural language processing technologies; She develops approaches for anticipating, measuring, and mitigating harms arising from language technologies, focusing on the complexities of language and language technologies in their social contexts, and on supporting NLP practitioners in their ethical work. She has also worked on using NLP approaches to examine language variation and change (computational sociolinguistics), for example developing models to identify language variation on social media.
                        </p>
                    </div>
                </div>
                <div class="speaker-container">
                    <div class="speaker-photo">
                        <div class="aspect-ratio aspect-ratio--1x1">
                            <img src="./assets/gagan.jpg" class="db bg-center cover aspect-ratio--object br-100" alt="Afternoon Keynote Speaker">
                        </div>
                    </div>

                    <div class="speaker-info">
                        <h2>Dr. Gagan Bansal</h2>
                        <p>
                            Gagan Bansal is a researcher at Microsoft Research, where he is part of the AI Frontiers group and co-leads research on AutoGen, a framework for building multi-agent AI systems. His work lies at the intersection of Artificial Intelligence and Human-Computer Interaction, with a focus on making AI systems more capable, interactive, and useful to people. Before joining Microsoft Research in 2022, Gagan completed his Ph.D. in Computer Science at the University of Washington, advised by Dan Weld. At UW, he was part of the Lab for Human-AI Interaction, where he studied how AI systems can complement human decision-making. At Microsoft, Gagan has been a driving force behind several open-source agentic projects, including: 
                        </p>
                        <ul>
                            <li>AutoGen, a widely adopted framework for multi-agent applications</li>
                            <li>AutoGen Studio, a low-code interface for creating agentic workflows</li>
                            <li>Magentic-One, a state-of-the-art multi-agent team for solving complex tasks</li>
                            <li>MarkitDown, a tool for converting large sets of files to markdown for LLMs</li>
                          </ul> 

                    </div>
                </div>
            </div>

            </div>
        </article>


        <article class="cf ph3 ph5-ns pv5" id="agenda">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Agenda
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <p class="f5 lh-copy mt0-ns">
                    The primary goal of this one-day workshop is to bring together HCI and AI researchers from academia, industry, and non-profits to share their ongoing efforts around evaluating and auditing language models.
                </p>
                <ul class="agenda-list">
                    <li>
                        <h3>Welcome</h3>
                        <p>Time: 9:00 AM - 9:15 AM</p>
                    </li>
                    <li>
                        <h3>Morning Keynote: Dr. Su Lin Blodgett</h3>
                        <p>Time: 9:15 AM - 10:15 AM</p>
                    </li>
                    <li>
                        <h3>Special Theme Lightning Talks A</h3>
                        <p>Time: 10:15 AM - 10:45 AM</p>
                    </li>
                    <li>
                        <h3>Poster Session A (in-person) // Oral Session (virtual)</h3>
                        <p>Time: 10:45 AM - 11:45 AM</p>
                    </li>
                    <li>
                        <h3>Group Activity I: What is "Context"?</h3>
                        <p>Time: 11:45 AM - 12:15 PM</p>
                    </li>
                    <li>
                        <h3>Lunch Break</h3>
                        <p>Time: 12:15 PM - 2:00 PM</p>
                    </li>
                    <li>
                        <h3>Afternoon Keynote: Dr. Gagan Bansal</h3>
                        <p>Time: 2:00 PM - 3:00 PM</p>
                    </li>
                    <li>
                        <h3>Special Theme Lightning Talks B</h3>
                        <p>Time: 3:00 PM - 3:30 PM</p>
                    </li>
                    <li>
                        <h3>Poster Session B (in-person) // Display of Virtual Posters </h3>
                        <p>Time: 3:30 PM - 4:30 PM</p>
                    </li>
                    <li>
                        <h3>Group Activity II: Challenges and Opportunities in Context-Dependent Evaluation & Auditing</h3>
                        <p>Time: 4:30 PM - 5:30 PM</p>
                    </li>
                    <li>
                        <h3>Closing Remark</h3>
                        <p>Time: 5:30 PM - 5:45 PM</p>
                    </li>
                </ul>
                <p class="f5 lh-copy mt0-ns">
                    All times displayed in the program are in local time (Yokohama, Japan).
                </p>
            </div>
        </article>

        <article class="cf ph3 ph5-ns pv5" id="accepted">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Accepted Work
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <p class="f5 lh-copy mt0-ns">
                    <h3> Special Theme Papers</h4>
                    <ul>
                        <li class="pv1"><b>PIFU: A novel framework to evaluate the interpretability of synthetic free-text explanations in digital mental health</b> - Y.H.P.P Priyadarshana, Ashala Senanayake, Zilu Liang <a href = "chi2025_papers/2_PIFU_A_novel_framework_to_ev.pdf">[Link]</a></li>
                        <li class="pv1"><b>Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation</b> - Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander Nicholas D'Amour <a href = "chi2025_papers/4_Bias_in_Language_Models_Beyo.pdf">[Link]</a></li>
                        <li class="pv1"><b>Evaluating the Potentials of LLMs in User-Controlled Content Filtering on Social Media</b> - Anna Ricarda Luther  <a href = "chi2025_papers/evaluating_potential_LLM.pdf">[Link]</a> </li>
                        <li class="pv1"><b>Step-By-Step Reasoning with Meta Cognitive Prompts to Reduce Contextual Hallucination</b> - Brian Miki, Nicholas Vincent <a href = "chi2025_papers/8_Step_By_Step_Reasoning_with_.pdf">[Link]</a></li>
                        <li class="pv1"><b>Backpropagating from Customer Success</b> - Midam Kim, Fabio Casati, Darrell Penta, Ihnaee Choi, Minyoung Kim  </li>
                        
                        <li class="pv1"><b>Aligning and Auditing Large Language Model (LLM) for Harmful Content Detection for Body Dissatisfaction and Eating Disorders (ED): Rule Development and Validation Process</b> - Pranita Shrestha, Jue Xie, Pari Delir Haghighi, Michelle Byrne, Roisin McNaney <a href = "chi2025_papers/aligning_and_auditing.pdf">[Link]</a></li>
                        <li class="pv1"><b>Copilot Arena: A Platform for Code LLM Evaluation in the Wild</b> - Wayne Chi, Valerie Chen, Anastasios Nikolas Angelopoulos, Wei-Lin Chiang, Aditya Mittal, Naman Jain, Tianjun Zhang, Ion Stoica, Chris Donahue, Ameet Talwalkar <a href = "chi2025_papers/14_Copilot_Arena_A_Platform_fo.pdf">[Link]</a></li>
                        <li class="pv1"><b>Fiction vs Friction: Challenges in Evaluating LLMs on Data Visualization Tasks</b> - Shani C Spivak, Melanie Tory <a href = "chi2025_papers/fiction_vs_friction.pdf">[Link]</a></li>
                        <li class="pv1"><b>A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems</b> - Carlos Rafael Catalan <a href = "chi2025_papers/17_A_Gamified_Evaluation_and_R.pdf">[Link]</a></li>
                        <li class="pv1"><b>From job titles to jawlines: Using context voids to study generative AI systems</b> - Shahan Ali Memon, Soham De, Sungha Kang, Riyan Mujtaba, Bedoor AlShebli, Katie Davis, Jaime Snyder, Jevin West <a href = "chi2025_papers/18_From_job_titles_to_jawlines.pdf">[Link]</a></li>

                        <li class="pv1"><b>Multi-Criteria Model Comparison for Large Language Models</b> - Jason L. Harman, Jaelle Scheuerman <a href = "chi2025_papers/multi_criteria_model.pdf">[Link]</a></li>
                        <li class="pv1"><b>Detecting Experiential Differences Between LLM Versions Using Psychometric Scales: a Journaling Case Study</b> - Willem van der Maden, Pavel Okopnyi, Frode Guribye, Simone Grassini, Jichen Zhu <a href = "chi2025_papers/detecting_experiential.pdf">[Link]</a></li>
                        <li class="pv1"><b>Caught in the Cascade: Why LLM Auditing is Missing the Middle</b> - Anna Neumann, Jat Singh <a href = "chi2025_papers/23_Caught_in_the_Cascade_Why_L.pdf">[Link]</a></li>
                        <li class="pv1"><b>Toward a Human-centered Evaluation Framework for Trustworthy LLM-powered GUI Agents</b> - Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li  <a href = "chi2025_papers/24_Toward_a_Human_centered_Eva.pdf">[Link]</a></li>
                        <li class="pv1"><b>LLMs Are Not Reliable Human Proxies to Study Affordances in Data Visualizations</b> - Kylie Lin, Chase Stokes, Cindy Xiong Bearfield  <a href = "chi2025_papers/26_LLMs_Are_Not_Reliable_Human.pdf">[Link]</a></li>

                        <li class="pv1"><b>LLM agents outperform Harvard negotiators</b> - Michael Cheng, Carolyn Zou, James Sebenius, Michael S. Bernstein </li>
                        <li class="pv1"><b>An Exploratory Analysis of Open Large Language Model on Conversational Safety Annotations</b> - Yutong Cao, Lisa Y.W. Tang </li>
                        <li class="pv1"><b>Understanding Human Heuristics in Context-Sensitive Image Captioning</b> - Yanru Jiang, Hongjing Lu, Rick Dale <a href = "chi2025_papers/30_Understanding_Human_Heurist.pdf">[Link]</a></li>
                        <li class="pv1"><b>Broadening Applications: Grounding LLM Development in Potential User Needs</b> - Kaitlyn Zhou, Kristina Gligoric, Myra Cheng, Vyoma Raman, Michelle S. Lam, Boluwatife Aminu, Caeley Woo, Michael Brockman, Dan Jurafsky</li>
                        <li class="pv1"><b>Chatbot Auditing and Evaluation Is (Sometimes) Ill-Posed</b> - Aspen Hopkins, Angie Boggust, Harini Suresh <a href = "chi2025_papers/34_Chatbot_Evaluation_Is_Somet.pdf">[Link]</a></li>

                        <li class="pv1"><b>DICE: A Framework for Dimensional and Contextual of Language Models</b> - Aryan Shrivastava, Paula Akemi Aoyagui <a href = "chi2025_papers/DICE_a_framework.pdf">[Link]</a></li>
                        <li class="pv1"><b>Designing Scalable and Transparent Interfaces for Multi-Criteria Evaluation of LLM Outputs</b> - Lakshya Sharma, Amin El Asery, Zahra Ashktorab, Qian Pan, Justin D. Weisz <a href = "chi2025_papers/41_Designing_Scalable_and_Tran.pdf">[Link]</a></li>
                        <li class="pv1"><b>Evaluating LLMs in Experiential Context: Insights from a Survey of Recent CHI Publications</b> - Christine Dierk, Jennifer Healey, Mustafa Doga Dogan <a href = "chi2025_papers/43_Evaluating_LLMs_in_Experien.pdf">[Link]</a></li>
                        <li class="pv1"><b>Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies</b> - Jonathan Sakunkoo, Annabella Sakunkoo <a href = "chi2025_papers/45_Name_of_Thrones_Evaluating_.pdf">[Link]</a></li>
                        <li class="pv1"><b>Can an LLM tell me if I can legally get an abortion?</b> - Ro Encarnación, Danaë Metaxa <a href = "chi2025_papers/51_Can_an_LLM_tell_me_if_I_can.pdf">[Link]</a></li>

                        <li class="pv1"><b>Evaluating Robustness in LLM-based Medical Chatbots</b> - Mukul Kumar, Karna Sai Nikhilesh Reddy, Alugubelli Dinesh Reddy <a href = "chi2025_papers/52_Evaluating_Robustness_in_LL.pdf">[Link]</a></li>
                    </ul>

                    <h3>(General) Papers</h4>
                    <ul>
                        <li class="pv1"><b>Navigating Uncertainty in Human-AI Relationships: Identifying Interactive Community Challenges as a Community-Driven Uncertainty Reduction Strategy</b> - Hongyuan Gan, Han Li, Zhan Jinyuan, Renwen Zhang   </li>
                        <li class="pv1"><b>Systematizing During Measurement Enables Broader Stakeholder Participation</b> - Hanna Wallach, Meera Desai, A. Feder Cooper, Angelina Wang, Chad Atalla, Agathe Balayn, Solon Barocas, Su Lin Blodgett, Alexandra Chouldechova, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Alexandra Olteanu, Nicholas J Pangakis, Stefanie Reed, Emily Sheng, Dan Vann, Jennifer Wortman Vaughan, Matthew Vogel, Hannah Washington, Abigail Z Jacobs</li>
                        <li class="pv1"><b>EvalAssist: A Human-Centered Tool for LLM-as-a-Judge</b> - Zahra Ashktorab, Werner Geyer, Michael Desmond, Elizabeth M. Daly, Martín Santillán Cooper, Qian Pan, Erik Miehling, Tejaswini Pedapati, Hyo Jin Do <a href = "chi2025_papers/11_EvalAssist_A_Human_Centered.pdf">[Link]</a></li>
                        <li class="pv1"><b>Exploring Bengali Creative Storytelling Capabilities of Large Language Models Across Cultural Variations</b> - Azmine Toushik Wasi, Raima Islam, Mst Rafia Islam, Farig Sadeque, Taki Hasan Rafi, Dong-Kyu Chae <a href = "chi2025_papers/16_Exploring_Bengali_Creative_.pdf">[Link]</a></li>
                        <li class="pv1"><b>AI Should Not Be an Imitation Game: Centaur Evaluations</b> - Andreas Haupt, Erik Brynjolfsson</li>

                        <li class="pv1"><b>Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content</b> - Yilang Peng, Sijia Qian, Yingdan Lu, Cuihua Shen </li>
                        <li class="pv1"><b>Can Large Language Models Grasp Concepts in Visual Content? A Case Study on YouTube Shorts about Depression</b> - Jiaying Lizzy Liu, Yiheng Su, Praneel Seth <a href = "chi2025_papers/35_Can_Large_Language_Models_G.pdf">[Link]</a></li>
                        <li class="pv1"><b>Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text</b> - Jennifer Healey, Laurie Byrum, Md Nadeem Akhtar, Surabhi Bhargava and Moumita Sinha <a href = "chi2025_papers/37_Developing_A_Framework_to_S.pdf">[Link]</a></li>
                        <li class="pv1"><b>No-Code Truman: Attempts to Enable Natural Language Revisions to a Real-World Code Base</b> - J.D. Zamfirescu-Pereira, Jessie Jia, Asad Nabi, Qian Yang  <a href = "chi2025_papers/no_code_truman.pdf">[Link]</a></li>
                        <li class="pv1"><b>VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures</b> - Yoo Yeon Sung, Hannah Kim, Dan Z <a href = "chi2025_papers/39_VeriLA_A_Human_Centered_Eva.pdf">[Link]</a></li>
                        
                        <li class="pv1"><b>Rethinking Theory of Mind Benchmarks: Uncovering the Limitations of Appropriating ToM Tasks to Evaluate Large Language Models</b> - Qiaosi Wang, Xuhui Zhou, Maarten Sap, Jodi Forlizzi, Hong Shen <a href = "chi2025_papers/40_Rethinking_Theory_of_Mind_B.pdf">[Link]</a></li>
                        <li class="pv1"><b>Evaligner: Automatic Prompt and Criteria Refinement from User Feedback</b> - Heechan Lee, Tae Soo Kim, Juho Kim <a href = "chi2025_papers/47_Evaligner_Automatic_Prompt_.pdf">[Link]</a></li>
                        <li class="pv1"><b>Meta-Evaluating Local LLMs: Rethinking Performance Metrics for Serious Games</b> - Andres Isaza-Giraldo, Paulo Bala, Lucas Pereira <a href = "chi2025_papers/48_Meta_Evaluating_Local_LLMs_.pdf">[Link]</a></li>
                        <li class="pv1"><b>Towards Use-Based Ethics Audits of LLM-Based Advice-Chatbots</b> - Tobias Christoph, Kees van Berkel, Katta Spiel <a href = "chi2025_papers/49_Towards_Use_Based_Ethics_Au.pdf">[Link]</a></li>
                        <li class="pv1"><b>Representational Harms in LLM-Generated Narratives Against Nationalities Located in the Global South</b> - Ilana Nguyen, Harini Suresh, Evan Shieh <a href = "chi2025_papers/50_Representational_Harms_in_L.pdf">[Link]</a></li>

                     </ul>
                </p>
            </div>
        </article>

        <article class="cf ph3 ph5-ns pv5" id="info">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Key Information
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <p><b>Submission deadline</b>: <del>February 17, 2025 (AoE)</del> <b>Extended to February 24, 2025 (AoE)</b></p>
                <p><b>Notification of acceptance</b>:<del> March 17, 2025 (AoE) </del> <b> Extended to March 27, 2025 (AoE)</b></p>
                <p><b>Workshop date</b>: April 26, 2025</p>
                <p><b>Workshop location</b>: Yokohama, Japan (Hybrid)</a></p>
                <p><b>Contact</b>: heal.workshop@gmail.com</a></p>
            </div>
        </article>

        <article class="cf ph3 ph5-ns pv5" id="cfp">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Call for Participation
                </h1>
            </header>
            <div class="fn fl-ns w-60-ns">
                <p class="f5 lh-copy mt0-ns">
                    We welcome participants who work on topics related to <b>supporting human-centered evaluation and auditing of language models</b>. Interested participants will be asked to contribute a short paper to the workshop. Topics of interest include, but not limited to:

                    <ul>
                        <li class="pv1">Empirical understanding of stakeholders' needs and goals of LLM evaluation and auditing</li>
                        <li class="pv1">Human-centered evaluation and auditing methods for LLMs</li>
                        <li class="pv1">Tools, processes, and guidelines for LLM evaluation and auditing</li>
                        <li class="pv1">Discussion of regulatory measures and public policies for LLM auditing</li>
                        <li class="pv1">Ethics in LLM evaluation and auditing</li>
                    </ul>

                    <b>Special Theme: Mind the Context.</b> We invite authors to engage with specific contexts in LLM evaluation and auditing. This theme could involve various topics: the usage contexts of LLMs (e.g., evaluating the capabilities and limitations of LLM applications in mental wellness care, or translation in high-stakes scenarios), the context of the evaluation/auditing itself (e.g., who are using LLM evaluation tools, and how should we design these tools with this context in mind?), and more. The term ''context'' is left open for interpretation, so to encourage diversity in how this this key concept is conceptualized and operationalized by workshop participants. Papers under this theme will be given a dedicated lightning talk session, as well as a special spotlight during the workshop's poster session.
                </p>
                <p class="f5 lh-copy mt0-ns">
                    <p class="pv1"><a style="font-weight: 700;">Submission Format:</a> 2 - 6 pages ACM double-column, excluding references.</p>
                    <p class="pv1"><a style="font-weight: 700;">Submission Types:</a> Position papers, full or in-progress empirical studies, literature reviews, system demos, method descriptions, or encore of published work. The submission will be non-archival. </p>
                    <p class="pv1"><a style="font-weight: 700;">Review Process:</a> Double-blind. Papers will be selected based on the quality of the submission and diversity of perspectives to allow for a meaningful exchange of knowledge between a broad range of stakeholders. </p>
                    <p><a style="font-weight: 700;">Templates: </a> <a class="accent-txt" href="https://www.acm.org/binaries/content/assets/publications/word_style/interim-template-style/interim-layout.docx">[Word]</a> <a class="accent-txt" href="https://portalparts.acm.org/hippo/latex_templates/acmart-primary.zip">[LaTex]</a> <a class="accent-txt" href="https://www.overleaf.com/latex/templates/acm-conference-proceedings-primary-article-template/wbvnghjbzwpc">[Overleaf]</a></p>
                    <p><a style="font-weight: 700;">Notes: </a>                    <ul>
                        <li class="pv1">We encourage authors who submit also to help with the review process.</li>
                        <li class="pv1">For an encore submission, you do not need to anonymize the submission. Encore submissions will go through a jury review process. </li>
                        <li class="pv1">Please use \documentclass[sigconf,anonymous]{acmart} for submission. </li>
                        <li class="pv1">Please be aware of OpenReview's moderation policy for newly created profiles: new profiles created without an institutional email will go through a moderation process that can take up to two weeks, while new profiles created with an institutional email will be activated automatically. </li>
                    </ul></p>
                </p>
                <p>
                    <a class="f6 link grow br3 ba bw1 ph3 pv2 mb2 dib accent-txt" href="https://openreview.net/group?id=ACM.org/CHI/2025/Workshop/HEAL" target="_blank">→ Submission Site</a>
                </p>
            </div>
        </article>

        <article class="cf ph3 ph5-ns pv5" id="info">
            <header class="fn fl-ns w-30-ns pr4-ns">
                <h1 class="f3 lh-title fw5 mb3 mt0 pt3 bt bw2 accent-txt">
                    Organizers
                </h1>
            </header>
            <div class="fn fl-ns w-70-ns">
                <section class="cf w-200 pa2-ns">
                    <div class="cf w-100 measure-wide">
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/yulu.png" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://yululiu.github.io/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Yu Lu Liu</p>
                                <p class="f6 fw4 mt2 black-60">Johns Hopkins University</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/deng.jpg" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://www.wesleydeng.com/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Wesley Hanwen Deng</p>
                                <p class="f6 fw4 mt2 black-60">Carnegie Mellon University</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/lam.jpg" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://michelle123lam.github.io/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Michelle S. Lam</p>
                                <p class="f6 fw4 mt2 black-60">Stanford University</p>
                            </a>
                        </div>
                    </div>
                
                    <div class="w-100 measure-wide">
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/eslami.jpg" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://www.motahhare.com/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Motahhare Eslami</p>
                                <p class="f6 fw4 mt2 black-60">Carnegie Mellon University</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/kim.jpg" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://juhokim.com/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Juho Kim</p>
                                <p class="f6 fw4 mt2 black-60">KAIST</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/liao.jpg" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="http://qveraliao.com/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Q. Vera Liao</p> 
                                <!--I don't get it, but the following spaces are necessary to perserve 3x3 profile format-->
                                <p class="f6 fw4 mt2 black-60">Microsoft Research &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
                            </a>
                        </div>
                    </div>
                    <div class="w-100 measure-wide">
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/wei.png" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://cocoxu.github.io/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Wei Xu</p>
                                <p class="f6 fw4 mt2 black-60">Georgia Institute of Technology</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/jekaterina.png" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://jeknov.github.io/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Jekaterina Novikova</p>
                                <p class="f6 fw4 mt2 black-60">AI Risk and Vulnerability Alliance</p>
                            </a>
                        </div>
                        <div class="fl w-third pa2">
                            <div class="aspect-ratio aspect-ratio--1x1">
                                <img src="./assets/xiao.png" class="db bg-center cover aspect-ratio--object br-100">
                            </div>
                            <a href="https://ziangxiao.com/" class="ph2 ph0-ns pb3 link db" target="_blank">
                                <p class="f5-ns mb0 fw6 black-90">Ziang Xiao</p>
                                <p class="f6 fw4 mt2 black-60">Johns Hopkins University</p>
                            </a>
                        </div>
                    </div>
                </section>
            </div>
        </article>
    </div>


    <footer class="pv4 ph3 ph5-m ph6-l mid-gray">
        <small class="f6 db tc">HEAL@CHI'25</small>
    </footer>


</body>

</html>